{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGPDVjw5oWrpEJMIK13UZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiaoyao-1996/micro-expression-recognition/blob/master/U1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioIVJJ1HLGPO",
        "outputId": "c5b527e3-f233-4f4c-d73c-763607906610"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "path = \"/content/drive/My Drive/miro\"\r\n",
        "\r\n",
        "os.chdir(path)\r\n",
        "os.listdir(path)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['main.py',\n",
              " 'happy',\n",
              " 'disgust',\n",
              " 'angry',\n",
              " '.idea',\n",
              " 'microexpstcnn_images.npy',\n",
              " 'microexpstcnn_labels.npy',\n",
              " 'weights-improvement-53-0.88.hdf5',\n",
              " 'microexpstcnn_val_images.npy',\n",
              " 'microexpstcnn_val_labels.npy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgK1BdUcNIRr"
      },
      "source": [
        "import os\r\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu\r\n",
        "import cv2\r\n",
        "import numpy\r\n",
        "import imageio\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from tensorflow.python.keras.layers.convolutional import Convolution3D, MaxPooling3D\r\n",
        "from keras.optimizers import SGD, RMSprop\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.python.keras.utils import np_utils, generic_utils\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn import preprocessing\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "import sys\r\n",
        "from keras.models import load_model\r\n",
        "import tensorflow as tf\r\n",
        "\r\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwZvx1xyNO0K"
      },
      "source": [
        "K.set_image_data_format('channels_last')\r\n",
        "\r\n",
        "image_rows, image_columns, image_depth = 64, 64, 41\r\n",
        "\r\n",
        "\r\n",
        "training_list = []\r\n",
        "angrypath = './angry/'\r\n",
        "happypath = './happy/'\r\n",
        "disgustpath = './disgust/'\r\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R3vdzDWNUa8"
      },
      "source": [
        "directorylisting = os.listdir(angrypath)\r\n",
        "for video in directorylisting:\r\n",
        "\tframes = []\r\n",
        "\tvideopath = angrypath + video\r\n",
        "\tframerange = os.listdir(videopath)\r\n",
        "\r\n",
        "\tfor frame in framerange:\r\n",
        "\t\timage = cv2.imread(videopath + \"/\" + frame)\r\n",
        "\t\timageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\r\n",
        "\t\tgrayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\r\n",
        "\t\tframes.append(grayimage)\r\n",
        "\tframes = numpy.asarray(frames)\r\n",
        "\tvideoarray = numpy.rollaxis(numpy.rollaxis(frames, 2, 0), 2, 0)\r\n",
        "\ttraining_list.append(videoarray)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCS17nUiNrTG"
      },
      "source": [
        "directorylisting = os.listdir(happypath)\r\n",
        "for video in directorylisting:\r\n",
        "\tframes = []\r\n",
        "\tvideopath = happypath + video\r\n",
        "\tframerange = os.listdir(videopath)\r\n",
        "\r\n",
        "\tfor frame in framerange:\r\n",
        "\t\timage = cv2.imread(videopath + \"/\" + frame)\r\n",
        "\t\timageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\r\n",
        "\t\tgrayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\r\n",
        "\t\tframes.append(grayimage)\r\n",
        "\tframes = numpy.asarray(frames)\r\n",
        "\tvideoarray = numpy.rollaxis(numpy.rollaxis(frames, 2, 0), 2, 0)\r\n",
        "\ttraining_list.append(videoarray)\r\n",
        "\r\n",
        "\r\n",
        "directorylisting = os.listdir(disgustpath)\r\n",
        "for video in directorylisting:\r\n",
        "\tframes = []\r\n",
        "\tvideopath = disgustpath + video\r\n",
        "\tframerange = os.listdir(videopath)\r\n",
        "\r\n",
        "\tfor frame in framerange:\r\n",
        "\t\timage = cv2.imread(videopath + \"/\" + frame)\r\n",
        "\t\timageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\r\n",
        "\t\tgrayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\r\n",
        "\t\tframes.append(grayimage)\r\n",
        "\tframes = numpy.asarray(frames)\r\n",
        "\t#print(frames)\r\n",
        "\tvideoarray = numpy.rollaxis(numpy.rollaxis(frames, 2, 0), 2, 0)\r\n",
        "\ttraining_list.append(videoarray)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io3NfJ6pN5yW",
        "outputId": "7939e843-42ff-4a10-b5a8-4f529cac03db"
      },
      "source": [
        "training_list = numpy.asarray(training_list)\r\n",
        "trainingsamples = len(training_list)\r\n",
        "\r\n",
        "\r\n",
        "traininglabels = numpy.zeros((trainingsamples, ), dtype = int)\r\n",
        "\r\n",
        "\r\n",
        "traininglabels[0:76] = 0\r\n",
        "traininglabels[76:170] = 1\r\n",
        "traininglabels[170:206] = 2\r\n",
        "\r\n",
        "traininglabels = np_utils.to_categorical(traininglabels, 3)\r\n",
        "\r\n",
        "training_data = [training_list, traininglabels]\r\n",
        "(trainingframes, traininglabels) = (training_data[0], training_data[1])\r\n",
        "training_set = numpy.zeros((trainingsamples,1, image_rows, image_columns,  image_depth))\r\n",
        "print(training_set.shape)\r\n",
        "for h in range(trainingsamples):\r\n",
        "\ttraining_set[h][0][:][:][:] = trainingframes[h,:,:,:]\r\n",
        "\r\n",
        "training_set = training_set.astype('float32')\r\n",
        "training_set -= numpy.mean(training_set)\r\n",
        "training_set /= numpy.max(training_set)\r\n",
        "#print(training_set)\r\n",
        "training_set=numpy.array(training_set)\r\n",
        "training_set=tf.transpose(training_set,[0, 4 ,2 ,3 ,1])\r\n",
        "print(training_set.shape)\r\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 1, 64, 64, 41)\n",
            "(6, 41, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-5GJCRtOLzg"
      },
      "source": [
        "# Save training images and labels in a numpy array\r\n",
        "numpy.save('/content/drive/My Drive/miro/microexpstcnn_images.npy', training_set)\r\n",
        "numpy.save('/content/drive/My Drive/miro/microexpstcnn_labels.npy', traininglabels)\r\n",
        "\r\n",
        "\r\n",
        "# Load training images and labels that are stored in numpy array\r\n",
        "training_set = numpy.load('/content/drive/My Drive/miro/microexpstcnn_images.npy')\r\n",
        "traininglabels =numpy.load('/content/drive/My Drive/miro/microexpstcnn_labels.npy')"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFPvOF46Ooc4",
        "outputId": "3f4836f0-e8ef-445d-82bd-abcd77f53544"
      },
      "source": [
        "# MicroExpSTCNN Model\r\n",
        "model = Sequential()\r\n",
        "model.add(Convolution3D(32, (3, 3, 15), input_shape=(image_depth ,image_rows, image_columns, 1), activation='relu'))\r\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))#init='normal',\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(3,))# init='normal'\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_13 (Conv3D)           (None, 39, 62, 50, 32)    4352      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 13, 20, 16, 32)    0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 13, 20, 16, 32)    0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 133120)            0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               17039488  \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 387       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 17,044,227\n",
            "Trainable params: 17,044,227\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDq8tkSKTBPH",
        "outputId": "a0f5b673-437d-4a4f-e6c0-28459a844f06"
      },
      "source": [
        "print(training_set.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 41, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfDscRri4IcQ"
      },
      "source": [
        "# Load pre-trained weights\r\n",
        "\"\"\"\r\n",
        "model.load_weights('/content/drive/My Drive/miro/weights-improvement-53-0.88.hdf5')\r\n",
        "\"\"\"\r\n",
        "filepath=\"/content/drive/My Drive/miro/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\r\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "JIw43_SP-fol",
        "outputId": "9f3b097d-3363-4743-b30f-19a1623cefb1"
      },
      "source": [
        "# Spliting the dataset into training and validation sets\r\n",
        "train_images, validation_images, train_labels, validation_labels =  train_test_split(training_set, traininglabels, test_size=0.2, random_state=4)\r\n",
        "\r\n",
        "\r\n",
        "# Save validation set in a numpy array\r\n",
        "\r\n",
        "numpy.save('/content/drive/My Drive/miro/microexpstcnn_val_images.npy', validation_images)\r\n",
        "numpy.save('/content/drive/My Drive/miro/microexpstcnn_val_labels.npy', validation_labels)\r\n",
        "\r\n",
        "\r\n",
        "# Load validation set from numpy array\r\n",
        "\r\n",
        "validation_images = numpy.load('/content/drive/My Drive/miro/microexpstcnn_val_images.npy')\r\n",
        "validation_labels = numpy.load('/content/drive/My Drive/miro/microexpstcnn_val_labels.npy')\r\n",
        "\r\n",
        "\r\n",
        "# Training the model\r\n",
        "hist = model.fit(train_images, train_labels, validation_data = (validation_images, validation_labels), callbacks=callbacks_list, batch_size = 1, shuffle=True)#nb_epoch = 100,\r\n",
        "\r\n",
        "# Finding Confusion Matrix using pretrained weights\r\n",
        "\"\"\"\r\n",
        "predictions = model.predict(validation_images)\r\n",
        "predictions_labels = numpy.argmax(predictions, axis=1)\r\n",
        "validation_labels = numpy.argmax(validation_labels, axis=1)\r\n",
        "cfm = confusion_matrix(validation_labels, predictions_labels)\r\n",
        "print (cfm)\r\n",
        "\"\"\""
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 838ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m       \u001b[0;31m# placeholders can cause formatting to fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m       \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-44f9473bf40a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#nb_epoch = 100,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Finding Confusion Matrix using pretrained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m       raise KeyError('Failed to format this callback filepath: \"{}\". '\n\u001b[0;32m-> 1430\u001b[0;31m                      'Reason: {}'.format(self.filepath, e))\n\u001b[0m\u001b[1;32m   1431\u001b[0m     self._write_filepath = distributed_file_utils.write_filepath(\n\u001b[1;32m   1432\u001b[0m         file_path, self.model.distribute_strategy)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Failed to format this callback filepath: \"/content/drive/My Drive/miro/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\". Reason: \\'val_acc\\''"
          ]
        }
      ]
    }
  ]
}